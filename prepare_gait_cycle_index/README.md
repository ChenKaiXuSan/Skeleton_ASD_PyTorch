# Preprocess the gait dataset

ä¸ºäº†åŠ é€Ÿè®¡ç®—ï¼Œåº”è¯¥å…ˆå¤„ç†å›¾ç‰‡ï¼Œç„¶åŽä¿å­˜æˆæ–‡ä»¶ï¼Œç„¶åŽå†è¯»å–æ–‡ä»¶ï¼Œè¿™æ ·çš„è¯ï¼Œå¯ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ã€‚
ä¹Ÿå°±æ˜¯è¯´éœ€è¦æƒ³ä¸€ä¸ªæ–‡ä»¶å¤„ç†è¿‡åŽåº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­çš„ã€‚

ä¾‹å¦‚,åªä½¿ç”¨æ‚£è€…æ­¥è¡Œçš„å‰åŠé˜¶æ®µæ¥è¿›è¡Œè®­ç»ƒçš„è¯ï¼Œ
å¦‚æžœåªæŠŠä¸€ä¸ªæ‚£è€…çš„ä¸è¡Œå‘¨æœŸåˆ†ä¸ºä¸¤éƒ¨åˆ†æ¥çœ‹çš„è¯ï¼Œ

ðŸ““å›¾åƒå¢žå¼ºçš„æ“ä½œï¼Œä»Žptæ–‡ä»¶ä¸­è¯»å–ä¹‹åŽå†è¿›è¡Œä¹Ÿæ˜¯å¯ä»¥çš„

## JSON file

ðŸ—’ï¸ Because I found that the .pt file is too large, so I use the json file to store the information of the gait cycle index.

## Format

**This script is used to the segmentation_dataset_512 dataset.**

To define the gait cycle in the video, and save the gait cycle index to json file.

The json file include: (in dict)
``` python
{
    "video_name": the video name,
    "video_path": the video path, relative path from /workspace/skeleton/data/segmentation_dataset_512,
    "frame_count": the raw frames of the video,
    "label": the label of the video,
    "disease": the disease of the video,
    "gait_cycle_index_bbox": the gait cycle index,
    "bbox_none_index": the bbox none index, when use yolo to get the bbox, some frame will not get the bbox.
    "bbox": the bbox, [n, 4] (cxcywh)
}
```

## Pipeline

The python file flow is:

``` mermaid
graph LR
    main.py --> preprocess.py --> yolov8.py
```

The data process pipeline is:

``` mermaid
graph LR
    A[video] --> B[object detection] --> C[BBOX] --> D[.json file]
```

## Usage

``` bash
python main.py
```

The json file will be saved in the indicate folder, like:
`~/dataset/segmentation_dataset_512/json/` folder.